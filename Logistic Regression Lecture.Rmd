##  Logistic Regression

# Part 1
```{r}
df.train <- read.csv('titanic_train.csv')
head(df.train)
str(df.train)
```

# Loading Libraries
```{r}
library(Amelia)
library(ggplot2)
```

```{r}
missmap(df.train,main = 'Missing Map', col = c('yellow','black'),legend=FALSE)
```

# Survived
```{r}
ggplot(df.train,aes(Survived)) + geom_bar()
```

# Pclass

```{r}
ggplot(df.train,aes(Pclass)) + geom_bar(aes(fill=factor(Pclass)))
```


# Sex
```{r}
ggplot(df.train,aes(Sex)) + geom_bar(aes(fill=factor(Sex)))
```

# Hist of Age

```{r}
ggplot(df.train,aes(Age)) + geom_histogram(bins=20,fill='blue',alpha=0.5)
```

# SibSp

```{r}
ggplot(df.train,aes(SibSp)) + geom_bar(aes(fill=factor(SibSp)))
```

# Fare Histogram

```{r}
ggplot(df.train,aes(Fare)) + geom_histogram(fill='green',color='black',alpha=0.5,bins=20)
```

# Boxplot Pclass

```{r}
plot <- ggplot(df.train,aes(Pclass,Age))
plot <- plot + geom_boxplot(aes(group=Pclass,fill=factor(Pclass),alpha=0.4))
plot + scale_y_continuous(breaks = seq(min(0),max(80),by=2)) + theme_bw()
```

# Imputation of Age Based on Class
```{r}
impute_age <- function(age,class){
out <- age
for (i in 1:length(age)){
  
  if (is.na(age[i])){
    
    if (class[i] == 1){
      out[i] <- 37
      
    }else if (class[i] == 2){
      out[i] <- 29
      
    }else{
      out[i] <- 24
    }
  }else{
    out[i]<-age[i]
  }
}
return(out)
}
```

# Building a Logistic Regression Model (Part 2)

```{r}
fixed.ages <- impute_age(df.train$Age,df.train$Pclass)
```

```{r}
df.train$Age <- fixed.ages
```

```{r}
missmap(df.train, main="Titanic Training Data - Missings Map", 
        col=c("yellow", "black"), legend=FALSE)
```

## Get the str of the data

```{r}
str(df.train)
```

## Remove What We Don't Use

```{r}
head(df.train,3)
```

## Relevant Columns for Training

```{r}
library(dplyr)
```

```{r}
df.train <- select(df.train,-PassengerId,-Name,-Ticket,-Cabin)
```
```{r}
head(df.train,3)
```

## Set Factor Columns

```{r}
str(df.train)
```

```{r}
df.train$Survived <- factor(df.train$Survived)
df.train$Pclass <- factor(df.train$Pclass)
df.train$Parch <- factor(df.train$Parch)
df.train$SibSp <- factor(df.train$SibSp)
```

## Train the Model

```{r}
log.model <- glm(formula=Survived ~ . , family = binomial(link='logit'),data = df.train)
summary(log.model)
```

## Predictting Using Test Cases

```{r}
library(caTools)
```

```{r}
set.seed(101)

split = sample.split(df.train$Survived, SplitRatio = 0.70)

final.train = subset(df.train, split == TRUE)
final.test = subset(df.train, split == FALSE)
```

## Final Logistic Model

```{r}
final.log.model <- glm(formula=Survived ~ . , family = binomial(link='logit'),data = final.train)
```

```{r}
summary(final.log.model)
```


## Checking Prediction Accuracy

```{r}
fitted.probabilities <- predict(final.log.model,newdata=final.test,type='response')
fitted.results <- ifelse(fitted.probabilities > 0.5,1,0)

misClasificError <- mean(fitted.results != final.test$Survived)
print(paste('Accuracy',1-misClasificError))
```

## Conculsion Matrix


```{r}
table(final.test$Survived, fitted.probabilities > 0.5)
```
